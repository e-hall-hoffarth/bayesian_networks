{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph \n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from notears_custom import utils\n",
    "from scipy import stats, linalg\n",
    "from itertools import chain, combinations, product\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import math\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm.notebook import tqdm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('C:/Users/ehall/Documents/thesis/bayesian_networks/data/rbc.csv')\n",
    "data = pd.read_csv('C:/Users/ehall/Documents/thesis/bayesian_networks/data/real_data.csv')\n",
    "# data = data.drop(['eps_g', 'eps_z', 'log_y', 'log_k', 'log_c', 'log_l','log_w','log_i'], axis=1)\n",
    "data = data.drop(list(['DATE', 'dk']), axis=1)\n",
    "data.columns = [col.replace(\" \", \"\") for col in data.columns]\n",
    "data = data.iloc[:,1:]\n",
    "# data.drop(['rb', 'l', 'n'], axis=1, inplace=True)\n",
    "\n",
    "# data = data.apply(lambda x: x - x.mean())\n",
    "# data = data.applymap(lambda x: x + np.random.normal(scale=1))\n",
    "\n",
    "shift_vars = data.columns.values\n",
    "shift = data.loc[:,shift_vars].shift()\n",
    "shift.columns = [str(col) + '_1' for col in shift.columns]\n",
    "data = pd.concat([data, shift], axis=1)\n",
    "data = data.iloc[1:,:]\n",
    "\n",
    "# data = data.iloc[:1000,:]\n",
    "\n",
    "# data = data[['rm', 'rk', 'z', 'y', 'w', 'u', 'c', 'i', 'g',\n",
    "#              'rm_1', 'rk_1', 'z_1', 'y_1', 'w_1', 'u_1', 'c_1', 'i_1', 'g_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dag():\n",
    "    \n",
    "    def __init__(self, m):\n",
    "        '''\n",
    "        m is a pandas DataFrame conaining an adjacency matrix\n",
    "        '''\n",
    "        self.m = m\n",
    "        self.nodes = self.m.columns.values\n",
    "        self.lags = np.array([n for n in self.nodes if '_1' in n])\n",
    "        if not all(self.m.columns.values == self.m.index.values):\n",
    "            raise ValueError('Invalid adjacency matrix (columns and rows are not the same)')\n",
    "        self.directed = self.directed()\n",
    "\n",
    "            \n",
    "    def parents(self, n):\n",
    "        '''\n",
    "        n is a node in the graph\n",
    "        '''\n",
    "        if n not in self.nodes:\n",
    "            raise ValueError('n is not in graph')\n",
    "        return self.m.loc[self.m.loc[:,n] != 0, n].index.values\n",
    "    \n",
    "    \n",
    "    def children(self, n):\n",
    "        '''\n",
    "        n is a node in the graph\n",
    "        '''\n",
    "        if n not in self.nodes:\n",
    "            raise ValueError('n is not in graph')\n",
    "        return self.m.loc[:,self.m.loc[n,:] != 0].columns.values\n",
    "    \n",
    "    \n",
    "    def directed(self):\n",
    "        return utils.is_dag(self.m.values)\n",
    "        \n",
    "    \n",
    "    def depth(self, n):\n",
    "        '''\n",
    "        n is a node in the graph\n",
    "        return the length of the shortest path to a root node\n",
    "        '''\n",
    "        if not self.directed:\n",
    "            raise ValueError('Cannot compute depth, graph is undirected')\n",
    "        if len(self.parents(n)) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 + max([self.depth(p) for p in self.parents(n)])\n",
    "    \n",
    "    \n",
    "    def root_nodes(self):\n",
    "        return np.array([n for n in self.nodes if len(self.parents(n)) == 0])\n",
    "        \n",
    "        \n",
    "    def isolated_nodes(self):\n",
    "        return np.array([n for n in d.nodes if (len(d.parents(n)) == 0) & (len(d.children(n)) == 0)])\n",
    "    \n",
    "    \n",
    "    def connected_roots(self):\n",
    "        return np.array([n for n in d.nodes if (len(d.parents(n)) == 0) & (len(d.children(n)) > 0)])\n",
    "    \n",
    "    \n",
    "    def structure(self):\n",
    "        M = self.m.copy()\n",
    "        M[M != 0] = 1\n",
    "        return M\n",
    "    \n",
    "    \n",
    "    def shd(self, d):\n",
    "        try:\n",
    "            return utils.count_accuracy(d.structure().values, self.structure().values)['shd']\n",
    "        except ValueError as e:\n",
    "            # Graph is not directed\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def impute(self, values):\n",
    "        na_nodes = values[values.isna()]\n",
    "        depth = 0\n",
    "        try:\n",
    "            max_depth = max([self.depth(n) for n in self.nodes])\n",
    "        except ValueError as e:\n",
    "            print('Cannot impute values as graph is not directed')\n",
    "            raise e\n",
    "        while depth <= max_depth:\n",
    "            for node in na_nodes.index:\n",
    "                if self.depth(node) == depth:\n",
    "                    values[node] = np.dot(self.m.loc[:,node], values.fillna(0))\n",
    "            depth += 1\n",
    "        return values\n",
    "\n",
    "\n",
    "    def calculate_irf(self, x_0, T=250, verbose=False):\n",
    "        if verbose:\n",
    "            print('Simulating irf...')\n",
    "        for lag in self.lags:\n",
    "            x_0[lag] = 0\n",
    "        irf = pd.DataFrame([self.impute(x_0)], columns=self.nodes)\n",
    "        for t in range(T-1):\n",
    "            if verbose:\n",
    "                print('Simulating t={} of {} ({}%)'.format(t+1, T, np.round(100 * ((t+1)/T), decimals=2)))\n",
    "            nr = pd.Series(np.full(len(self.nodes), np.nan), index=self.nodes)\n",
    "            for lag in self.lags:\n",
    "                nr[lag] = irf.iloc[-1,:][lag.rstrip('_1')]\n",
    "            nr = self.impute(nr)    \n",
    "            irf = irf.append(nr, ignore_index=True)\n",
    "        irf.loc[:,'t'] = range(T)\n",
    "        irf.set_index('t', inplace=True)\n",
    "        irf.drop(self.lags, axis=1, inplace=True)\n",
    "        return irf\n",
    "\n",
    "\n",
    "    def plot_irf(self, irf, layout=None):\n",
    "        if layout is None:\n",
    "            side = math.ceil(math.sqrt(len(irf.columns)))\n",
    "            layout = (side, side)\n",
    "        axes = irf.plot(subplots=True, layout=layout, \n",
    "                        color=\"black\", legend=False)\n",
    "        for ax, name in zip(axes.flatten(), irf.columns.values):\n",
    "            ax.axhline(y=0, color=\"red\")\n",
    "            ax.set_title(name)\n",
    "        return plt\n",
    "    \n",
    "    \n",
    "    def plot_structure(self):\n",
    "        M = self.m.values\n",
    "        g = igraph.Graph.Adjacency((M != 0.0).tolist())\n",
    "        g.es['weight'] = M[M.nonzero()]\n",
    "        g.vs['label'] = self.nodes\n",
    "        g.vs['color'] = 'white'\n",
    "        g.vs['size'] = 45\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roles():\n",
    "    def __init__(self, exo_states, endo_states, controls, names):\n",
    "        self.exo_states = exo_states\n",
    "        self.endo_states = endo_states\n",
    "        self.controls = controls\n",
    "        self.exo_states_1 = [x + '_1' for x in self.exo_states]\n",
    "        self.endo_states_1 = [x + '_1' for x in self.endo_states]\n",
    "        self.controls_1 = [x + '_1' for x in self.controls]\n",
    "        self.names = names\n",
    "        assert len(self.exo_states) + len(self.endo_states) + len(self.controls) == len(names)\n",
    "        \n",
    "        self.exo_states_idx = np.where([x in exo_states for x in names])[0]\n",
    "        self.endo_states_idx = np.where([x in endo_states for x in names])[0]\n",
    "        self.controls_idx = np.where([x in controls for x in names])[0]\n",
    "        self.lag_exo_states_idx = np.array([x + len(names) for x in self.exo_states_idx], dtype=int).reshape(-1)\n",
    "        self.lag_endo_states_idx = np.array([x + len(names) for x in self.endo_states_idx], dtype=int).reshape(-1)\n",
    "        self.lag_controls_idx = np.array([x + len(names) for x in self.controls_idx], dtype=int).reshape(-1)\n",
    "        \n",
    "    \n",
    "    def lag_idx(self, x):\n",
    "        return x + len(self.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lag(n):\n",
    "    return n + '_1'\n",
    "\n",
    "\n",
    "def current(n):\n",
    "    return n.rstrip('_1')\n",
    "\n",
    "                    \n",
    "def partial_correlation(y, x, z, data):\n",
    "    if len(z) == 0:\n",
    "        pcorr = stats.pearsonr(data[:,y], data[:,x])\n",
    "    else:\n",
    "        model_y = LinearRegression(fit_intercept=False, normalize=True)\n",
    "        model_x = LinearRegression(fit_intercept=False, normalize=True)\n",
    "        model_y.fit(data[:,z], data[:,y])\n",
    "        model_x.fit(data[:,z], data[:,x])\n",
    "        resid_y = data[:,y] - model_y.predict(data[:,z])\n",
    "        resid_x = data[:,x] - model_x.predict(data[:,z])\n",
    "        pcorr = stats.pearsonr(resid_y, resid_x) # return p-value\n",
    "    \n",
    "    return pcorr\n",
    "\n",
    "\n",
    "def fisher_z(pcorr, z, data):\n",
    "    z = math.sqrt(len(data) - len(z) - 3)*math.log((1+pcorr)/(1-pcorr))/2\n",
    "    pval = 2*(1-stats.norm.cdf(abs(z)))\n",
    "    return (z, pval)\n",
    "\n",
    "\n",
    "def potential_states(x, max_states=None):\n",
    "    limit = len(x) - 1 if max_states is None else max_states + 1\n",
    "    exo_states = chain.from_iterable(combinations(x, r) for r in range(limit))\n",
    "    for exo in exo_states:\n",
    "        y = [z for z in x if z not in exo]\n",
    "        endo_states = chain.from_iterable(combinations(y, r) for r in range(limit-len(exo)))\n",
    "        for endo in endo_states:\n",
    "            controls = [z for z in x if z not in endo and z not in exo]\n",
    "            yield roles(exo, endo, controls, x)\n",
    "    return None\n",
    "\n",
    "\n",
    "def sigma_sq(Y, Y_hat):\n",
    "    n = Y.shape[0]\n",
    "    sigma_sq = (1/n)*np.mean(np.sum((Y - Y_hat)**2))\n",
    "    return sigma_sq\n",
    "\n",
    "\n",
    "def llik(Y, Y_hat):\n",
    "    n = Y.shape[0]\n",
    "    sigma = sigma_sq(Y, Y_hat)\n",
    "    ll = (-1 * (n/2) * np.log(2*math.pi) - \n",
    "               (n/2) * np.log(sigma) - \n",
    "               (1/(2*sigma)) * np.sum((Y - Y_hat)**2))\n",
    "    return ll\n",
    "    \n",
    "    \n",
    "def loglik(roles, data):\n",
    "    ll = 0\n",
    "\n",
    "    t_controls = np.append(roles.controls_idx, roles.endo_states_idx)\n",
    "    n = data.shape[0]\n",
    "    p = t_controls.shape[0]\n",
    "    X_hat = np.empty((n,0))\n",
    "    if len(roles.exo_states) > 0:\n",
    "        for lag_exo_state, exo_state in zip(roles.exo_states_idx, roles.lag_exo_states_idx):\n",
    "            X = data[:,lag_exo_state]\n",
    "            Y = data[:,exo_state]\n",
    "            model = sm.OLS(Y, X)\n",
    "            model_fit = model.fit()\n",
    "            Y_hat = model_fit.predict(X)\n",
    "            \n",
    "            ll += llik(Y, Y_hat)\n",
    "            X_hat = np.append(X_hat.reshape(n,-1), model_fit.predict(X).reshape(n,-1), axis=1)\n",
    "        \n",
    "    # X_hat = np.append(X_hat.reshape(n,-1), data[:,roles.lag_endo_states_idx], axis=1)\n",
    "    X_hat = np.append(data[:,roles.exo_states_idx], data[:,roles.lag_endo_states_idx], axis=1)\n",
    "    \n",
    "    if X_hat.shape[1] > 0:\n",
    "        for control in t_controls:\n",
    "            Y = data[:,control]\n",
    "            model = sm.OLS(Y, X_hat)\n",
    "            model_fit = model.fit()\n",
    "            Y_hat = model_fit.predict(X_hat)\n",
    "            ll += llik(Y, Y_hat)\n",
    "   \n",
    "    else: # No states in model\n",
    "        for control in t_controls:\n",
    "            ll += llik(data[:,control], np.zeros((n,1)))\n",
    "        \n",
    "    return ll\n",
    "        \n",
    "\n",
    "def aic(L, roles, data):\n",
    "    k = 2*(len(roles.exo_states) + \n",
    "           (len(roles.exo_states) + len(roles.endo_states))*\n",
    "           (len(roles.controls) + len(roles.endo_states)) )\n",
    "    n = data.shape[0]\n",
    "    return 2*k - 2*L\n",
    "\n",
    "    \n",
    "def bic(L, roles, data):\n",
    "    k = 2*(len(roles.exo_states) + \n",
    "           (len(roles.exo_states) + len(roles.endo_states))*\n",
    "           (len(roles.controls) + len(roles.endo_states)) )\n",
    "    n = data.shape[0]\n",
    "    return k * np.log(n) - 2 * L\n",
    "\n",
    "\n",
    "def mse(roles, data):\n",
    "    t_controls = np.append(roles.controls_idx, roles.endo_states_idx)\n",
    "    n = data.shape[0]\n",
    "    p = t_controls.shape[0]\n",
    "    X_hat = np.empty((n,0))\n",
    "    if len(roles.exo_states) > 0:\n",
    "        for lag_exo_state, exo_state in zip(roles.exo_states_idx, roles.lag_exo_states_idx):\n",
    "            X = data[:,lag_exo_state]\n",
    "            Y = data[:,exo_state]\n",
    "            model = sm.OLS(Y, X)\n",
    "            model_fit = model.fit()\n",
    "            X_hat = np.append(X_hat.reshape(n,-1), model_fit.predict(X).reshape(n,-1), axis=1) \n",
    "    X_hat = np.append(X_hat.reshape(n,-1), data[:,roles.lag_endo_states_idx], axis=1)\n",
    "    if X_hat.shape[1] > 0:\n",
    "        X = np.append(data[:,roles.exo_states_idx], data[:,roles.lag_endo_states_idx], axis=1)\n",
    "        Y = data[:,t_controls]\n",
    "        model = sm.OLS(Y, X_hat)\n",
    "        model_fit = model.fit()\n",
    "        Y_hat = model_fit.predict(X)\n",
    "        mse = np.mean(np.sum((Y - Y_hat)**2, axis=0))\n",
    "    else:\n",
    "        mse = (1/n)*np.sum((data[:,t_controls])**2)\n",
    "    \n",
    "    return mse\n",
    "    \n",
    "    \n",
    "def score_tests(roles, data):\n",
    "    L = loglik(roles, data.values)\n",
    "    b = bic(L, roles, data.values) \n",
    "    a = aic(L, roles, data.values)\n",
    "    m = mse(roles, data.values)\n",
    "    tests = {\n",
    "        'loglik': L,\n",
    "        'bic': b,\n",
    "        'aic': a,\n",
    "        'mse': m\n",
    "    }  \n",
    "    return tests\n",
    "\n",
    "\n",
    "def contraint_tests(roles, names, data):\n",
    "    tests = []\n",
    "    # Test that controls and endogenous states are conditionally independent\n",
    "    # Conditional on lag of endo states and exo states\n",
    "    for (x, y) in combinations(np.append(roles.controls_idx, roles.endo_states_idx), 2):\n",
    "        z = np.append(roles.lag_endo_states_idx, roles.exo_states_idx)\n",
    "        p = partial_correlation(x, y, z, data=data.values)\n",
    "        pcorr = p[0]\n",
    "        pval = p[1]\n",
    "        tests.append({'x': names[x],\n",
    "                      'y': names[y],\n",
    "                      'z': names[z],\n",
    "                      'pcorr': pcorr,\n",
    "                      'pval': pval})\n",
    "                    \n",
    "    # Test that current controls and endo states are independent of \n",
    "    # lagged exo states conditional on current exo states\n",
    "    for (x, y) in itertools.product(np.append(roles.controls_idx, roles.endo_states_idx), roles.exo_states_idx):\n",
    "        y_1 = roles.lag_idx(y)\n",
    "        z = np.array([y], dtype=int)\n",
    "        p = partial_correlation(x, y_1, z, data=data.values)\n",
    "        pcorr = p[0]\n",
    "        pval = p[1]\n",
    "        tests.append({'x': names[x],\n",
    "                      'y': names[y_1],\n",
    "                      'z': names[z],\n",
    "                      'pcorr': pcorr,\n",
    "                      'pval': pval}) \n",
    "    \n",
    "    # Test that lagged endo states are marginally independent of\n",
    "    # current exo states\n",
    "    for (x, y) in itertools.product(roles.lag_endo_states_idx, roles.exo_states_idx):\n",
    "        p = partial_correlation(x, y, [], data=data.values)\n",
    "        pcorr = p[0]\n",
    "        pval = p[1]\n",
    "        tests.append({'x': names[x],\n",
    "                      'y': names[y],\n",
    "                      'z': [],\n",
    "                      'pcorr': pcorr,\n",
    "                      'pval': pval}) \n",
    "    \n",
    "    # Test that current controls are independent of their lags\n",
    "    # conditional on lagged endo states\n",
    "    for x in roles.controls_idx:\n",
    "        p = partial_correlation(x, roles.lag_idx(x), roles.lag_endo_states_idx, data=data.values)\n",
    "        pcorr = p[0]\n",
    "        pval = p[1]\n",
    "        tests.append({'x': names[x],\n",
    "                      'y': names[roles.lag_idx(x)],\n",
    "                      'z': names[roles.lag_endo_states_idx],\n",
    "                      'pcorr': pcorr,\n",
    "                      'pval': pval}) \n",
    "    return tests\n",
    "\n",
    "\n",
    "def evaluate_states(data, roles, tests=['score', 'constraint'], alpha=0.05, verbose=False):\n",
    "    if verbose: \n",
    "        print('Evaluating states {}'.format(list(roles.exo_states) + [es + '_1' for es in roles.endo_states]))\n",
    "    names = np.array(list(roles.names) + [x + '_1' for x in roles.names]).reshape(-1)\n",
    "    results = {}\n",
    "    results['exo_states'] = roles.exo_states\n",
    "    results['endo_states'] = roles.endo_states\n",
    "    results['controls'] = roles.controls\n",
    "    if 'constraint' in tests:\n",
    "        ct = contraint_tests(roles, names, data) \n",
    "        m = len(ct)\n",
    "        valid = all([test['pval'] > (alpha/2)/m for test in ct])\n",
    "        if valid and verbose:\n",
    "            print('Valid states found: {}'.format(np.append(roles.exo_states, roles.endo_states)))\n",
    "        results['valid'] = valid\n",
    "        results['mean_pval'] = np.mean([test['pval'] for test in ct])\n",
    "        results['max_pval'] = max([test['pval'] for test in ct])\n",
    "        results['min_pval'] = min([test['pval'] for test in ct])\n",
    "        results['contraint_tests'] = ct\n",
    "    if 'score' in tests: \n",
    "        st = score_tests(roles, data)             \n",
    "        results = {**results, **st}\n",
    "    results['nstates'] = len(roles.endo_states) + len(roles.exo_states)\n",
    "    results['nexo'] = len(roles.exo_states)\n",
    "    results['nendo'] = len(roles.endo_states)\n",
    "    results['roles'] = roles\n",
    "    return results\n",
    "\n",
    "\n",
    "def choose_states(data, alpha=0.05, tests=['score', 'constraint'], max_states=None, verbose=False):\n",
    "    results = pd.DataFrame(columns=['valid', 'states', 'mean_pval', 'max_pval', 'min_pval', 'tests'])\n",
    "    variables = data.columns.values[:np.int64(len(data.columns.values)/2)]\n",
    "    ps = tqdm(potential_states(variables, max_states=max_states))\n",
    "    for states in ps:\n",
    "        result = evaluate_states(data, states, tests, alpha=alpha, verbose=verbose)\n",
    "        results = results.append(result, ignore_index=True)\n",
    "    return results\n",
    "\n",
    "        \n",
    "def choose_states_parallel(data, alpha=0.05, tests=['score', 'constraints'], max_states=None, verbose=False):\n",
    "    variables = data.columns.values[:np.int64(len(data.columns.values)/2)]\n",
    "    states = potential_states(variables, max_states=max_states)\n",
    "    results = Parallel(n_jobs=cpu_count())(delayed(evaluate_states)(data, state, tests, alpha, verbose) for state in tqdm(states))\n",
    "    return pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "def make_adjacency(exo_states, endo_states, controls, data):\n",
    "    data_names = data.columns.values.tolist()\n",
    "    data_current = [name for name in data_names if '_1' not in name]\n",
    "    implied_names = exo_states + endo_states + controls\n",
    "    \n",
    "    for name in implied_names:\n",
    "        if name not in data_names:\n",
    "            raise ValueError('Name {} missing from data'.format(name))\n",
    "        if str(name) + '_1' not in data_names:\n",
    "            raise ValueError('Lag of name {} missing from data'.format(name))\n",
    "        if any([name not in data_names for name in implied_names]) or any([name not in implied_names for name in data_current]):\n",
    "            print(data_current)\n",
    "            print(implied_names)\n",
    "            raise ValueError('Implied names and data do not align')\n",
    "    \n",
    "    names = data_names\n",
    "    d = len(data.columns)\n",
    "    result = pd.DataFrame(np.zeros((d, d)), columns=names, index=names)\n",
    "    \n",
    "    for exo_state in exo_states:\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(data[[exo_state + '_1']], data[exo_state])\n",
    "        result.loc[exo_state + '_1', exo_state] = model.coef_[0]\n",
    "        \n",
    "    for endo in endo_states + controls:\n",
    "        regressors = [es + '_1' for es in endo_states] + exo_states\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(data[regressors], data[endo])\n",
    "        coefs = {}\n",
    "        for i in range(len(regressors)):\n",
    "            coefs[regressors[i]] = model.coef_[i]\n",
    "        for x in regressors:\n",
    "            result.loc[x, endo] = coefs[x]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = choose_states_parallel(data, alpha=0.05, tests=['score'], max_states=6, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='mse', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['valid']].sort_values(by=['nstates', 'loglik'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='mean_pval', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = data.columns.values[:int(len(data.columns.values)/2)]\n",
    "exo_names = ['z', 'g']\n",
    "endo_names = ['k']\n",
    "controls = [x for x in variables if x not in exo_names and x not in endo_names]\n",
    "r = roles(exo_names, endo_names, controls, variables)\n",
    "\n",
    "print(mse(r, data.values))\n",
    "print(bic(loglik(r, data.values), r, data.values))\n",
    "print(loglik(r, data.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An agnostic way of choosing states from the data\n",
    "optimal_states = results[results['valid']].sort_values(by=['nstates', 'min_pval'], ascending=[True, False]).iloc[0,:]['states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_names = list(optimal_states.exo_states)\n",
    "endo_names = list(optimal_states.endo_states)\n",
    "controls = optimal_states.controls\n",
    "\n",
    "print(exo_names)\n",
    "print(endo_names)\n",
    "print(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = make_adjacency(exo_names, endo_names, controls, data=data)\n",
    "real_dag = dag(m)\n",
    "\n",
    "x_0 = pd.Series(np.full(len(real_dag.nodes), np.nan), index=real_dag.nodes)\n",
    "shock_amt = 1\n",
    "shock_var = 'z'\n",
    "if shock_var in exo_names:\n",
    "    shock_index = np.where(data.columns.values == shock_var)[0][0]\n",
    "elif shock_var + '_1' in endo_names:\n",
    "    shock_index = np.where(data.columns.values == shock_var.rstrip('_1'))[0][0]\n",
    "else:\n",
    "    raise ValueError('Cannot shock control variable {}'.format(shock_var))\n",
    "\n",
    "x_0[shock_index] = shock_amt\n",
    "x_0[int(len(real_dag.nodes)/2):] = 0\n",
    "\n",
    "real_irf = real_dag.calculate_irf(x_0, T=25)\n",
    "plt = real_dag.plot_irf(real_irf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = data.columns.values[:int(len(data.columns.values)/2)]\n",
    "# Some guess at what the states may be\n",
    "exo_names = ['z', 'n']\n",
    "endo_names = ['rm', 'g', 'w', 'u', 'c', 'l']\n",
    "controls = [x for x in variables if x not in exo_names and x not in endo_names]\n",
    "r = roles(exo_names, endo_names, controls, variables)\n",
    "\n",
    "print(exo_names)\n",
    "print(endo_names)\n",
    "print(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = make_adjacency(exo_names, endo_names, controls, data=data)\n",
    "real_dag = dag(m)\n",
    "\n",
    "x_0 = pd.Series(np.full(len(real_dag.nodes), np.nan), index=real_dag.nodes)\n",
    "shock_amt = 1\n",
    "shock_var = 'rm'\n",
    "shock_index = np.where(data.columns.values == shock_var)[0][0]\n",
    "x_0[shock_index] = shock_amt\n",
    "x_0[int(len(real_dag.nodes)/2):] = 0\n",
    "\n",
    "real_irf = real_dag.calculate_irf(x_0, T=25)\n",
    "plt = real_dag.plot_irf(real_irf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = data.columns.values[:int(len(data.columns.values)/2)]\n",
    "# Some guess at what the states may be\n",
    "exo_names = []\n",
    "endo_names = []\n",
    "controls = [x for x in variables if x not in exo_names and x not in endo_names]\n",
    "r = roles(exo_names, endo_names, controls, variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bic(L, roles, data):\n",
    "    # First term is number of slope coefficients, second is number of sigmas\n",
    "    k = (len(roles.exo_states) + (len(roles.exo_states) + len(roles.endo_states)) * (len(roles.controls) + len(roles.endo_states))) + (len(roles.exo_states) + 1)\n",
    "    n = data.shape[0]\n",
    "    return k * np.log(n) - 2 * L\n",
    "\n",
    "def loglik(roles, data):\n",
    "    ll = 0\n",
    "    # Get predicted values of exo_states\n",
    "    for exo_state, lag_exo_state in zip(roles.exo_states_idx, roles.lag_exo_states_idx):\n",
    "        X_1 = data[:,lag_exo_state]\n",
    "        Y_1 = data[:,exo_state]\n",
    "        model_1 = sm.OLS(Y_1, X_1)\n",
    "        model_1_fit = model_1.fit()\n",
    "        ll += model_1.loglike(model_1_fit.params)\n",
    "\n",
    "    t_controls = np.append(roles.controls_idx, roles.endo_states_idx)\n",
    "    t_states = np.append(roles.exo_states_idx, roles.lag_endo_states_idx)\n",
    "    if t_states.shape[0] > 0:\n",
    "        # Predict current endo states and controls using predicted exo states and past endo states\n",
    "        X_2 = data[:,t_states]\n",
    "        Y_2 = data[:,t_controls]\n",
    "        model_2 = sm.OLS(Y_2, X_2)\n",
    "        model_2_fit = model_2.fit()\n",
    "        ll += model_2.loglike(model_2_fit.params)\n",
    "    else:\n",
    "        sigma_sq = (1/data.shape[0])*np.sum((data[:,t_controls])**2)\n",
    "        ll += -1 * (data.shape[0]/2) * np.log(2*math.pi) - (data.shape[0]/2) * np.log(sigma_sq) - (1/(2*sigma_sq)) * np.sum((data[:,t_controls])**2)\n",
    "\n",
    "    return ll\n",
    "\n",
    "L = loglik(r, data.values)\n",
    "b = bic(L, r, data.values)\n",
    "\n",
    "print(L)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['x', 'y', 'pcorr', 'pval(t)'])\n",
    "for x in list(combinations(controls, 2)):\n",
    "    df = df.append({'x': x[0],\n",
    "                    'y': x[1],\n",
    "                    'z': exo_states + endo_states,\n",
    "                    'pcorr': partial_correlation(x[0], x[1], exo_states + endo_states, data=data)[0],\n",
    "                    'pval(t)': partial_correlation(x[0], x[1], exo_states + endo_states, data=data)[1]},\n",
    "                   ignore_index=True)\n",
    "df.sort_values(by='pval(t)', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,['g', 'z']]\n",
    "Y_1 = data.loc[:, 'y']\n",
    "Y_2 = data.loc[:, 'i']\n",
    "Y = data.loc[:, ['y', 'i']]\n",
    "\n",
    "model_1 = sm.OLS(Y_1, X)\n",
    "model_1_fit = model_1.fit()\n",
    "model_1_ll = model_1.loglike(model_1_fit.params)\n",
    "\n",
    "model_2 = sm.OLS(Y_2, X)\n",
    "model_2_fit = model_2.fit()\n",
    "model_2_ll = model_2.loglike(model_2_fit.params)\n",
    "\n",
    "model = sm.OLS(Y, X)\n",
    "model_fit = model.fit()\n",
    "model_ll = model.loglike(model_fit.params)\n",
    "\n",
    "print(model_1_ll + model_2_ll)\n",
    "print(model_ll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
